# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10PgvwlDpnpF-DibkvJa2oWAHb2FV3Gxc
"""

# ==============================================
# üìä Analyse compl√®te du dataset Regensburg Pediatric Appendicitis
# Source : UCI Machine Learning Repository
# ==============================================

# Installer le package si n√©cessaire
!pip install ucimlrepo seaborn scikit-learn --quiet

# Importation des librairies n√©cessaires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from ucimlrepo import fetch_ucirepo
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# ==============================================
# üß© 1. Chargement du dataset
# ==============================================
dataset = fetch_ucirepo(id=938)
X = dataset.data.features
y = dataset.data.targets

print("‚úÖ Dataset charg√© avec succ√®s !\n")
print("Dimensions des donn√©es :", X.shape)
print("\nAper√ßu du jeu de donn√©es :")
display(X.head())

print("\nAper√ßu des cibles :")
display(y.head())

# ==============================================
# üß† 2. Informations g√©n√©rales et m√©tadonn√©es
# ==============================================
print("\n=== üßæ M√©tadonn√©es ===")
print(dataset.metadata)

print("\n=== üìö Informations sur les variables ===")
print(dataset.variables)

# ==============================================
# üîç 3. Exploration des donn√©es
# ==============================================
print("\n=== Informations g√©n√©rales sur les variables ===")
print(X.info())

print("\n=== Statistiques descriptives ===")
display(X.describe())

print("\n=== Valeurs manquantes ===")
print(X.isnull().sum())

# Fusion pour simplifier les visualisations
df = pd.concat([X, y], axis=1)

# ==============================================
# üìä 4. Visualisations exploratoires
# ==============================================

# Distribution des variables num√©riques
num_cols = X.select_dtypes(include=np.number).columns

plt.figure(figsize=(15, 8))
X[num_cols].hist(bins=15, figsize=(15, 8), edgecolor='black')
plt.suptitle("Distribution des variables num√©riques", fontsize=16)
plt.show()

# Corr√©lation entre variables num√©riques
plt.figure(figsize=(12, 10))
sns.heatmap(X.corr(), cmap='coolwarm', annot=True, fmt=".2f")
plt.title("Matrice de corr√©lation entre variables")
plt.show()

# Si la cible est binaire, on affiche les comparaisons
if y.shape[1] == 1:
    target_col = y.columns[0]
    plt.figure(figsize=(6, 4))
    sns.countplot(x=target_col, data=y, palette='viridis')
    plt.title("R√©partition de la variable cible")
    plt.show()

    # Comparaison de quelques variables avec la cible
    for col in num_cols[:4]:
        plt.figure(figsize=(6, 4))
        sns.boxplot(x=target_col, y=col, data=df, palette='Set2')
        plt.title(f"{col} selon la cible")
        plt.show()

# ==============================================
# ‚öôÔ∏è 5. Exemple de mod√©lisation simple
# ==============================================
print("\n=== üöÄ Mod√©lisation : R√©gression Logistique ===")

if y.shape[1] == 1:
    target_col = y.columns[0]
    X_train, X_test, y_train, y_test = train_test_split(X, y[target_col], test_size=0.25, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = LogisticRegression(max_iter=500)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print("\nRapport de classification :")
    print(classification_report(y_test, y_pred))

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title("Matrice de confusion")
    plt.xlabel("Pr√©diction")
    plt.ylabel("R√©el")
    plt.show()

# ==============================================
# üß© 6. Interpr√©tation rapide
# ==============================================
print("""
üìà L‚Äôanalyse ci-dessus permet :
- d‚Äôidentifier les distributions des variables cliniques,
- d‚Äôobserver les corr√©lations entre variables,
- de v√©rifier la capacit√© du mod√®le √† distinguer les cas d‚Äôappendicite,
- et de rep√©rer les variables les plus discriminantes.
""")