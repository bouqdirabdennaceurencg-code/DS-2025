# Estimation of Obesity Levels â€“ Complete ML Pipeline  
## README.md

## ğŸ“˜ Project Overview  
This project provides a complete, endâ€‘toâ€‘end Machine Learning pipeline for the **Estimation of Obesity Levels dataset (UCI ID: 544)**.  
It includes data loading, preprocessing, exploratory data analysis (EDA), feature engineering, model comparison, hyperparameter tuning, and final evaluation â€” all in a single reproducible Google Colab notebook.

---

## ğŸ“‚ Project Structure
- `notebook.ipynb` â€” Complete technical implementation (Python)
- `requirements.txt` â€” Dependencies required to run the notebook
- `README.md` â€” Project documentation and overview  
- (Optional) Generated visuals & exports from EDA and model evaluation

---

## âš™ï¸ Installation

1. **Clone or download the repository**
```
git clone <your_repo_url>
cd <repo_folder>
```

2. **Install dependencies**
```
pip install -r requirements.txt
```

3. **Open the notebook**
You can run the notebook locally or upload it to **Google Colab**.

---

## ğŸ“Š Dataset Description  
- **Name**: Estimation of Obesity Levels Based on Eating Habits and Physical Condition  
- **Source**: UCI Machine Learning Repository  
- **Type**: Classification  
- **Objective**: Predict the obesity level of individuals based on lifestyle, dietary habits, and physical condition.

The dataset contains both **numeric** and **categorical** variables, making it suitable for supervised machine learning using preprocessing pipelines.

---

## ğŸ§ª Notebook Workflow Summary

### âœ”ï¸ 1. Data Loading  
The dataset is fetched automatically using the `ucimlrepo` library.

### âœ”ï¸ 2. Preprocessing  
Includes:
- Duplicate removal  
- Missing value imputation  
- Oneâ€‘hot encoding of categorical features  
- Standardization of numerical features  

### âœ”ï¸ 3. Feature Engineering  
A synthetic variable (`numeric_risk_score`) is created to capture aggregated risk patterns.

### âœ”ï¸ 4. Exploratory Data Analysis (EDA)  
The notebook provides:
- Distributions of numerical features  
- Target class distribution  
- Boxplots  
- Correlation heatmap  

### âœ”ï¸ 5. Machine Learning Models Tested  
The following models were compared using **crossâ€‘validation (Accuracy)**:
- Logistic Regression  
- Random Forest Classifier  
- Gradient Boosting Classifier  

### âœ”ï¸ 6. Hyperparameter Optimization  
A **RandomizedSearchCV** was used to optimize a Random Forest model.

### âœ”ï¸ 7. Final Evaluation  
The best model (optimized Random Forest) was evaluated on the test set with:
- Classification report  
- Confusion matrix  
- AUCâ€‘ROC (multiclass OVR)

---

## ğŸ† Results Summary

- The optimized **Random Forest** model achieved the **best accuracy** during crossâ€‘validation.
- The **test set evaluation** showed strong predictive performance, balanced across obesity classes.
- Feature engineering and preprocessing pipelines contributed significantly to model stability.
- The workflow is fully automated and ready for production-level enhancement.

---

## ğŸš€ How to Use This Project  
1. Install dependencies  
2. Run the notebook from start to finish  
3. Use the model template to extend experiments or deploy the classifier  

---

## ğŸ“œ License  
This project is provided for academic and research purposes.

---

## ğŸ‘¤ Author  
Generated automatically using ChatGPT â€” ready for academic submission or professional ML documentation.
